{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started: Fine-tuning a model for Multi Label Classification task\n",
    "\n",
    "**Learning Objectives** - By the end of this quickstart tutorial, you'll know how to create a pipeline to fine-tune a model for multi label classification task on Azure Machine Learning studio.\n",
    "\n",
    "This tutorial covers:\n",
    "\n",
    "- Connect to workspace\n",
    "- Set up a compute resource on the Azure Machine Learning Studio via sdk\n",
    "- Create arguments to be passed for each component for fine-tuning a model for multi label classification\n",
    "- Build a end-to-end pipeline to fine-tune a model for multi label classification\n",
    "    - prepares data for finetuning\n",
    "    - fine-tunes the model\n",
    "    - registers the model\n",
    "- Submit the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependencies installation\n",
    "Before starting off, if you are running the notebook on Azure Machine Learning Studio or running first time locally, you will need the following packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-ai-ml==1.0.0\n",
    "! pip install azure-identity\n",
    "! pip install datasets==2.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Azure Machine Learning workspace\n",
    "\n",
    "Before we dive in the code, you'll need to connect to your workspace. The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning.\n",
    "\n",
    "We are using `DefaultAzureCredential` to get access to workspace. `DefaultAzureCredential` should be capable of handling most scenarios. If you want to learn more about other available credentials, go to [set up authentication doc](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication?tabs=sdk), [azure-identity reference doc](https://learn.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python).\n",
    "\n",
    "Replace `<AML_WORKSPACE_NAME>`, `<RESOURCE_GROUP>` and `<SUBSCRIPTION_ID>` with their respective values in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1671036247844
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "\n",
    "subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "resource_group = \"<RESOURCE_GROUP>\"\n",
    "workspace_name = \"<AML_WORKSPACE_NAME>\"\n",
    "experiment_name = \"AzureML-Train-Finetune-Samples\"      # can rename to any valid name\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "workspace_ml_client = MLClient(\n",
    "        credential,\n",
    "        subscription_id,\n",
    "        resource_group,\n",
    "        workspace_name,\n",
    "    )\n",
    "\n",
    "registry_ml_client = MLClient(\n",
    "    credential,\n",
    "    subscription_id,\n",
    "    resource_group,\n",
    "    registry_name=\"azureml-preview\",\n",
    ")\n",
    "\n",
    "preprocess_cluster_name = None\n",
    "finetune_cluster_name = None\n",
    "managed_identity_cluster_name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create compute\n",
    "\n",
    "In order to finetune a model on Azure Machine Learning studio, you will need to create a compute resource first. **Creating a compute will take 3-4 minutes.** \n",
    "\n",
    "For additional references, see [Azure Machine Learning in a Day](https://github.com/Azure/azureml-examples/blob/main/tutorials/azureml-in-a-day/azureml-in-a-day.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create CPU compute for model selection and data preprocess components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1671036280618
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "preprocess_cluster_name = \"sample-preprocess-cluster\"\n",
    "new_compute = AmlCompute(\n",
    "    name=preprocess_cluster_name,\n",
    "    size=\"Standard_D12\",\n",
    ")\n",
    "print(\"Creating/updating compute\")\n",
    "poller = workspace_ml_client.compute.begin_create_or_update(new_compute)\n",
    "poller.wait()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create GPU compute for finetune\n",
    "\n",
    "The recommended GPU compute SKUs can be found [here](https://learn.microsoft.com/en-us/azure/virtual-machines/ncv3-series) and [here](https://learn.microsoft.com/en-us/azure/virtual-machines/ndv2-series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1671036310817
    }
   },
   "outputs": [],
   "source": [
    "finetune_cluster_name = \"sample-finetune-cluster\"\n",
    "\n",
    "new_compute = AmlCompute(\n",
    "    name=finetune_cluster_name,\n",
    "    size=\"Standard_ND40rs_v2\",\n",
    "    max_instances=1 # Change this if you want to use multi node\n",
    ")\n",
    "\n",
    "print(\"Creating/updating compute\")\n",
    "poller = workspace_ml_client.compute.begin_create_or_update(new_compute)\n",
    "poller.wait()\n",
    "gpus_per_node = 8 # This varies with the compute SKU selected for finetune component\n",
    "num_nodes = 1 # For multi node training set it to > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create managed identity compute for registring the finetuned model (Optional)\n",
    "\n",
    "> **Note**: The `managed_identity_resource_id` must have Contributor access to the resource group as scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1671036311241
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import IdentityConfiguration, ManagedIdentityConfiguration\n",
    "\n",
    "managed_identity_cluster_name = \"sample-managed-id-cluster\"\n",
    "managed_identity_resource_id = \"<REPLACE WITH YOUR MANAGED IDENTITY RESOURCE ID>\"\n",
    "\n",
    "try:\n",
    "    # Note - create different cluster if necessary only else use preprocess_compute\n",
    "    uai = ManagedIdentityConfiguration(resource_id=managed_identity_resource_id)\n",
    "    identity_config = IdentityConfiguration(type=\"UserAssigned\", user_assigned_identities=[uai])\n",
    "\n",
    "    new_compute = AmlCompute(\n",
    "        name=managed_identity_cluster_name,\n",
    "        size=\"Standard_D12\",\n",
    "        identity=identity_config,\n",
    "    )\n",
    "\n",
    "    print(\"Creating/updating compute\")\n",
    "    poller = workspace_ml_client.compute.begin_create_or_update(new_compute)\n",
    "    poller.wait()\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create managed identity compute: {e}\")\n",
    "    managed_identity_cluster_name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create arguments to be passed to each component\n",
    "\n",
    "The detailed arguments for each component can be found at:\n",
    "- Model Selection - [model_selector_component.md](../../docs/component_docs/model_selector_component.md)\n",
    "- Data Pre Processing - [preprocess_component.md](../../docs/component_docs/preprocess_component.md)\n",
    "- Fine Tuning - [finetune_component.md](../../docs/component_docs/finetune_component.md)\n",
    "- Evaluate Model - [evaluate_model.md](../../docs/component_docs/evaluate_model.md)\n",
    "- Register - [register_component.md](../../docs/component_docs/register_component.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection_args = {\n",
    "  \"huggingface_id\": \"bert-base-uncased\"\n",
    "}\n",
    "\n",
    "preprocess_args = {\n",
    "  \"sentence1_key\": \"sentence\",\n",
    "  \"sentence2_key\": None,\n",
    "  \"label_key\": \"labels\",\n",
    "}\n",
    "\n",
    "finetune_args = {\n",
    "  \"lora_alpha\": 128,\n",
    "  \"lora_r\": 8,\n",
    "  \"lora_dropout\": 0.0,\n",
    "  \"epochs\": 10,\n",
    "  \"optimizer\": \"adamw_torch\",\n",
    "  \"learning_rate\": 2e-5,\n",
    "  \"train_batch_size\": 1,\n",
    "  \"valid_batch_size\": 1,\n",
    "  \"apply_deepspeed\": \"false\",\n",
    "  \"apply_ort\": \"false\",\n",
    "  \"apply_lora\": \"false\",\n",
    "  \"merge_lora_weights\": \"true\",\n",
    "  \"auto_find_batch_size\": \"false\",\n",
    "  \"save_as_mlflow_model\": \"true\",\n",
    "  \"evaluation_strategy\": \"steps\",\n",
    "  \"evaluation_steps_interval\": 0.25,\n",
    "  \"logging_strategy\": \"steps\",\n",
    "  \"logging_steps\": 100,\n",
    "}\n",
    "\n",
    "model_evaluation_args = {\n",
    "    \"task\": \"text-classification-multilabel\",\n",
    "    \"test_data_label_column_name\": \"labels\",\n",
    "    \"test_data_input_column_names\": \"sentence\",\n",
    "    \"device\": \"gpu\"\n",
    "}\n",
    "\n",
    "model_registration_args = {\n",
    "  \"name_for_registered_model\": \"sample_model_multi_label_classification\",\n",
    "  \"model_type\": \"mlflow_model\",\n",
    "  \"registry_name\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset for fine-tuning\n",
    "\n",
    "We can use a standard hugging-face dataset. For our current sample we are using dataset from local path `datasets`. You can change it to your dataset path.\n",
    "\n",
    "The dataset directory path being provided must have the following file names:\n",
    "- [train.jsonl](datasets/train.jsonl)\n",
    "- [validation.jsonl](datasets/validation.jsonl)\n",
    "- [test.jsonl](datasets/test.jsonl)\n",
    "\n",
    "Each file must be of `jsonl` format with following keys and values:\n",
    "- sentence_1 key (string, required)\n",
    "- sentence_2 key (string, optional)\n",
    "- label key (integer/string, required)\n",
    "\n",
    "Sample example line - {\"sentence1\": \"This is a sample sentence1 text\", \"sentence2\": \"This is a sample sentence2 text\", \"label\": \"['sample_label_x', 'sample_label_y']\"}\n",
    "You can also checkout [train.jsonl](datasets/train.jsonl), [validation.jsonl](datasets/validation.jsonl) and [test.jsonl](datasets/test.jsonl) for sample dataset format. \n",
    "\n",
    "Sample dataset schema as follows:\n",
    "```\n",
    "{\"text\":\"Thank you friend\",\"labels\":[15],\"id\":\"eeqd04y\",\"labels_str\":\"['15']\"}\n",
    "{\"text\":\"Happy to be able to help.\",\"labels\":[17],\"id\":\"efeu6uo\",\"labels_str\":\"['17']\"}\n",
    "{\"text\":\"that is what retardation looks like\",\"labels\":[27],\"id\":\"eeb9aft\",\"labels_str\":\"['27']\"}\n",
    "{\"text\":\"I miss them being alive\",\"labels\":[16,25],\"id\":\"ee8mzwa\",\"labels_str\":\"['16', '25']\"}\n",
    "{\"text\":\"Super, thanks\",\"labels\":[15],\"id\":\"ef462jc\",\"labels_str\":\"['15']\"}\n",
    "```\n",
    "The additional columns like `id`, `labels` will be excluded.\n",
    "\n",
    "For additional references see Sequence Classification Inputs in [preprocess_component.md](../../docs/component_docs/preprocess_component.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1671036311721
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_dir = \"./datasets/\"\n",
    "dataset_dir = os.path.abspath(dataset_dir)\n",
    "train_file = os.path.join(dataset_dir, \"train.jsonl\")\n",
    "validation_file = os.path.join(dataset_dir, \"validation.jsonl\")\n",
    "test_file = os.path.join(dataset_dir, \"test.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline job\n",
    "\n",
    "Let's create e2e pipeline job so that we can submit a pipeline to Azure Machine Learning Studio.\n",
    "\n",
    "Create the pipeline with multi label classification components for fine-tuning a model. Optionally register the fine-tuned model to workspace. It will show in `Models`.\n",
    "\n",
    "> **Note**: The pipeline job registers the fine-tuned model based on the `managed_identity_cluster_name` arg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1671036313875
    }
   },
   "outputs": [],
   "source": [
    "model_selector_func = registry_ml_client.components.get(name=\"textclassificationmultilabel_modelselection\", label=\"latest\")\n",
    "preprocess_func = registry_ml_client.components.get(name=\"textclassificationmultilabel_datapreprocessing\", label=\"latest\")\n",
    "finetune_func = registry_ml_client.components.get(name=\"textclassificationmultilabel_finetuning\", label=\"latest\")\n",
    "registration_func = registry_ml_client.components.get(name=\"register_model\", label=\"latest\")\n",
    "model_evaluation_func = registry_ml_client.components.get(name=\"evaluate_model\", label=\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utility function to create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1671036313995
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.entities import CommandComponent, Job, Component\n",
    "from azure.ai.ml import PyTorchDistribution, Input\n",
    "\n",
    "@pipeline()\n",
    "def create_pipeline():\n",
    "    \"\"\"Create pipeline.\"\"\"\n",
    "\n",
    "    model_selector: CommandComponent = model_selector_func(**model_selection_args)\n",
    "    model_selector.code = None\n",
    "    model_selector.compute = preprocess_cluster_name\n",
    "\n",
    "    preprocess: CommandComponent = preprocess_func(\n",
    "        model_path=model_selector.outputs[\"output_dir\"], \n",
    "        train_file_path = Input(type=\"uri_file\", path=train_file),\n",
    "        valid_file_path = Input(type=\"uri_file\", path=validation_file),\n",
    "        **preprocess_args\n",
    "    )\n",
    "    preprocess.code = None  # dirty workaround for dpv2\n",
    "    preprocess.compute = preprocess_cluster_name\n",
    "\n",
    "    finetune: CommandComponent = finetune_func(\n",
    "        model_path=model_selector.outputs[\"output_dir\"],\n",
    "        dataset_path=preprocess.outputs[\"output_dir\"],\n",
    "        **finetune_args,\n",
    "    )\n",
    "    finetune.code = None\n",
    "    finetune.compute = finetune_cluster_name\n",
    "    finetune.distribution = PyTorchDistribution(process_count_per_instance=gpus_per_node)\n",
    "    finetune.resources.instance_count = num_nodes\n",
    "\n",
    "    model_evaluation = model_evaluation_func(\n",
    "        test_data=Input(type=\"uri_file\", path=validation_file),\n",
    "        mlflow_model=finetune.outputs[\"mlflow_model_folder\"],\n",
    "        **model_evaluation_args,\n",
    "    )\n",
    "    \n",
    "    model_evaluation.code = None\n",
    "    model_evaluation.compute = finetune_cluster_name\n",
    "\n",
    "    if managed_identity_cluster_name is not None:\n",
    "        \n",
    "        registration: CommandComponent = registration_func(\n",
    "            model_path=finetune.outputs[\"mlflow_model_folder\"], **model_registration_args\n",
    "        )\n",
    "        registration.code = None\n",
    "        registration.compute = managed_identity_cluster_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create and submit sample pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1671036314772
    }
   },
   "outputs": [],
   "source": [
    "pipeline_object = create_pipeline()\n",
    "# print(pipeline_object)\n",
    "pipeline_object.display_name = model_selection_args[\"huggingface_id\"] + \"_pipeline_run_\" + \"multilabel\"\n",
    "\n",
    "print(\"Submitting pipeline\")\n",
    "\n",
    "pipeline_run = workspace_ml_client.jobs.create_or_update(pipeline_object, experiment_name=experiment_name)\n",
    "\n",
    "print(f\"Pipeline created. URL: {pipeline_run.studio_url}\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
