# <component>
$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json

name: azureml_textclassificationsinglelabel_deploy
version: 0.0.1
display_name: Deploy for TextClassificationSingleLabel
is_deterministic: True
type: command
description: Component to deploy finetuned model for single label classification task
inputs:
  model_checkpoint_dir:
    type: uri_folder
    optional: True
    description: The input path that contains the model files
  deployment_name:
    type: string
    optional: False
    description: The input path that contains the model files
  deepspeed_config:
    type: uri_file
    optional: True
    description: If apply_deepspeed is set to True, this file will be used as deepspeed config
  registry_name:
    type: string
    optional: True
    description: The name of the registry
  deployment_env_name:
    type: string
    optional: True
    description: The name of the environment to be deployed at online endpoint
  name_for_registered_model:
    type: string
    optional: False
    default: inferencemodel
    description: The name you want to give to the registered model
  endpoint_name:
    type: string
    optional: False
    default: inference-end-point
    description: The name of the endpoint to deploy the model to
  instance_type:
    type: string
    optional: False
    default: Standard_F8s_v2
    description: The instance type to use for the deployment
  instance_count:
    type: integer
    optional: False
    default: 1
    description: Number of vms for the deployment
  max_concurrent_requests_per_instance:
    type: integer
    optional: True
    default: 1
    description: Maximum concurrent requests to be handled per instance
  request_timeout_ms:
    type: integer
    optional: True
    default: 5000
    description: Request timeout in ms. Max limit is 90000.
  max_queue_wait_ms:
    type: integer
    optional: True
    default: 500
    description: Maximum queue wait time of a request in ms
  apply_ort:
    type: string
    optional: "True"
    default: "false"
    description: If set to true, will use the ONNXRunTime training

  apply_deepspeed:
    type: string
    optional: "True"
    default: "false"

  sentence1_key:
    type: string
    optional: True
    description: sentence1 key name
  sentence2_key:
    type: string
    optional: True
    description: sentence2 key name
  label_key:
    type: string
    optional: True
    description: label key name
  batch_size:
    type: integer
    optional: True
    default: 4
    description: Validation batch size
  precision:
    type: integer
    optional: True
    default: 32
    description: Apply mixed precision training. This can reduce memory footprint by performing operations in half-precision.
code: ../deploy_model
environment: azureml://registries/azureml-preview/environments/finetune-deploy-acpt-pytorch-111-py38-cuda113-gpu/versions/0.0.1
resources:
  instance_count: 1
command: python deploy.py --deployment_name ${{inputs.deployment_name}} $[[--model_checkpoint_dir ${{inputs.model_checkpoint_dir}}]] $[[--registry_name ${{inputs.registry_name}}]] $[[--deployment_env_name ${{inputs.deployment_env_name}}]] --endpoint_name ${{inputs.endpoint_name}}  --name_for_registered_model ${{inputs.name_for_registered_model}} --instance_type ${{inputs.instance_type}} --instance_count ${{inputs.instance_count}} $[[--max_concurrent_requests_per_instance ${{inputs.max_concurrent_requests_per_instance}}]] $[[--request_timeout_ms ${{inputs.request_timeout_ms}}]] $[[--max_queue_wait_ms ${{inputs.max_queue_wait_ms}}]] $[[--sentence1_key ${{inputs.sentence1_key}}]] $[[--sentence2_key ${{inputs.sentence2_key}}]] $[[--label_key ${{inputs.label_key}}]] $[[--batch_size ${{inputs.batch_size}}]] $[[--precision ${{inputs.precision}}]] $[[--apply_ort ${{inputs.apply_ort}}]] $[[--apply_deepspeed ${{inputs.apply_deepspeed}}]] $[[--deepspeed_config ${{inputs.deepspeed_config}}]]